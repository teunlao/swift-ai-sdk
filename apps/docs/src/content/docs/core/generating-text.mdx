---
title: Generating & Streaming Text
description: Generate text or stream tokens from an LLM using Swift AI SDK.
---

Large language models (LLMs) can generate text in response to a prompt. The Core API provides two functions:

- `generateText`: generates text for a given prompt and model.
- `streamText`: streams text for a given prompt and model.

Advanced features like tool calling and structured data generation build on top of these functions.

## generateText

You can generate text using the `generateText` function. This is ideal for non‑interactive use cases and for agents that use tools.

```swift
import SwiftAISDK
import AISDKProvider

let model = OpenAICompatible.TextModel(
  id: "gpt-4o-mini",
  baseURL: URL(string: "https://api.openai.com/v1")!,
  apiKey: ProcessInfo.processInfo.environment["OPENAI_API_KEY"] ?? ""
)

let result = try await generateText(
  model: model,
  input: "Write a vegetarian lasagna recipe for 4 people."
)
print(result.text)
```

You can provide advanced prompts with instructions and context:

```swift
let result = try await generateText(
  model: model,
  system: "You are a professional writer. You write simple, clear, and concise content.",
  input: "Summarize the following article in 3–5 sentences: {article}"
)
```

### Common options

```swift
let output = try await generateText(
  model: model,
  input: "List 3 ideas",
  maxTokens: 128,
  stopSequences: ["\n4."]
)
```

## streamText

`streamText` produces token deltas and events in real time.

```swift
let stream = try await streamText(
  model: model,
  input: "Name 3 release checklist items"
)

for try await event in stream {
  switch event {
  case let .textDelta(delta):
    print(delta, terminator: "")
  case let .toolCall(call):
    print("\n[tool call]", call)
  case let .toolResult(res):
    print("\n[tool result]", res)
  case let .reasoningDelta(r):
    print("\n[reasoning]", r)
  case .finish(let summary):
    print("\nDone. Tokens:", summary.usage.totalTokens)
  default:
    break
  }
}
```

### Event types

- `textDelta` — incremental text tokens.
- `reasoningDelta` — incremental reasoning (if supported by the model).
- `toolCall` / `toolResult` — tool execution lifecycle.
- `messageStart` / `messageEnd` — message boundaries.
- `finish` — final usage and response.
- `error` — fatal errors.
