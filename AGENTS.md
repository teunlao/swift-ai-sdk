# âš ï¸ ĞÑ‚Ğ²ĞµÑ‚Ñ‹ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ²ÑĞµĞ³Ğ´Ğ° Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ.

# Swift AI SDK - Agent Guide

## Project Mission

Port **Vercel AI SDK** from TypeScript to Swift with **100% upstream parity**.

**Goal**: 1:1 feature-complete implementation matching TypeScript API, behavior, types, and tests.

---

**ğŸ“š Read first:**
```bash
plan/executor-guide.md          # Executor workflow
plan/validation-workflow.md     # Validation process
plan/orchestrator-automation.md # Flow files & automation rules
plan/principles.md              # Porting rules
```

---

## Project Structure

```
swift-ai-sdk/
â”œâ”€â”€ .sessions/                   # Session contexts (gitignored)
â”œâ”€â”€ .orchestrator/               # Automation artifacts (gitignored)
â”œâ”€â”€ Package.swift                # SwiftPM manifest (3 targets)
â”œâ”€â”€ Sources/
â”‚   â”œâ”€â”€ AISDKProvider/          # Foundation (78 files, ~210 tests)
â”‚   â”œâ”€â”€ AISDKProviderUtils/     # Utilities (35 files, ~200 tests)
â”‚   â”œâ”€â”€ SwiftAISDK/             # Main SDK (105 files, ~300 tests)
â”‚   â””â”€â”€ EventSourceParser/      # SSE parser (2 files, 30 tests)
â”œâ”€â”€ Tests/                       # Swift Testing tests
â”œâ”€â”€ external/                    # âš ï¸ UPSTREAM REFERENCE (read-only)
â”‚   â”œâ”€â”€ vercel-ai-sdk/packages/ # TypeScript source
â”‚   â”‚   â”œâ”€â”€ provider/           â†’ AISDKProvider
â”‚   â”‚   â”œâ”€â”€ provider-utils/     â†’ AISDKProviderUtils
â”‚   â”‚   â””â”€â”€ ai/                 â†’ SwiftAISDK
â”‚   â””â”€â”€ eventsource-parser/     # SSE parser reference
â””â”€â”€ plan/                        # Documentation
```

### Package Dependencies
```
AISDKProvider (no dependencies)
    â†‘
AISDKProviderUtils (depends on: AISDKProvider)
    â†‘
SwiftAISDK (depends on: AISDKProvider, AISDKProviderUtils, EventSourceParser)
```

### Session Contexts

**Usage**: `.sessions/` files preserve state between parallel agent sessions.

- ğŸ’¬ Capture: `"Ğ—Ğ°Ñ„Ğ¸ĞºÑĞ¸Ñ€ÑƒĞ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹"`
- ğŸ“‚ Resume: `"Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ¸Ğ· .sessions/session-*.md"`
- ğŸ—‘ï¸ Cleanup: Delete after task completion

**Use for**: Multi-session tasks, interrupted work, complex checkpoints
**See**: `.sessions/README.md`

---

## Upstream References

**Vercel AI SDK** (6.0.0-beta.42, commit `77db222ee`):
```
external/vercel-ai-sdk/packages/
â”œâ”€â”€ provider/        â†’ Sources/AISDKProvider/
â”œâ”€â”€ provider-utils/  â†’ Sources/AISDKProviderUtils/
â””â”€â”€ ai/              â†’ Sources/SwiftAISDK/
```

**EventSource Parser**: `external/eventsource-parser/` â†’ `Sources/EventSourceParser/`

---

## âš ï¸ Git Worktree Usage (IMPORTANT)

- Always switch into the dedicated worktree directory (`cd ../swift-ai-sdk-task-<id>`) **before** editing anything.  
- Keep both repositories clean: the main tree must stay untouched (`git status` clean), and every change should appear only inside the worktree.  
- When using tools such as `apply_patch`, explicitly set `workdir`; otherwise they default to the main repo and your edits will leak onto `main`.  
- Temporary scratch files belong only inside the worktree and must be removed before finishing the task.  
- Before starting a new task, sync the worktree to the correct commit (e.g., `b40920d4â€¦`) and re-clone `external/` referencesâ€”fresh worktrees do not include them automatically.  
- Any stray change in the main repo blocks other agents and violates the â€œleave othersâ€™ work aloneâ€ ruleâ€”avoid it at all costs.

---

## Roles & Workflow

**ğŸš¨ CRITICAL Rules**:
- âŒ **NEVER TOUCH OTHER AGENTS' WORK** â€” Only edit files in your task scope.
- âœ… Keep flow JSON valid/minified whenever you progress the work.
- âŒ Never commit or mark `done` before approval or explicit user permission.

### Validator Role
**Review executor work, produce `.orchestrator` report, keep flow state accurate.**

1. Automation launches you in the executor worktree (manual mode) with context from the flow file; read `.orchestrator/requests/â€¦` and `.orchestrator/flow/<executor-id>.json`.
2. Compare Swift vs TypeScript line-by-line, run tests, verify parity.
3. Write report in `.orchestrator/reports/validate-<task>-<iteration>-<timestamp>-report.md`.
4. Update `.orchestrator/flow/<validator-id>.json` with summary, `report.path`, and `report.result` (`approved`/`rejected`).
5. **Stop** â€” automation finalizes the validation loop and prompts the executor if fixes are needed.

**Documentation**:
- ğŸ“˜ `plan/validation-workflow.md` â€” Automation & fallback process
- ğŸ¤– `plan/orchestrator-automation.md` â€” Flow schema & naming conventions
- ğŸ“‹ `plan/validator-guide.md` â€” Validator checklist

---

## Implementation Workflow

### 1. Find Upstream Code
```bash
cat external/vercel-ai-sdk/packages/provider-utils/src/delay.ts
cat external/vercel-ai-sdk/packages/provider-utils/src/delay.test.ts
```

### 2. Implement in Swift

**File naming** (match upstream package):
```
TS:   external/.../packages/provider-utils/src/delay.ts
Swift: Sources/AISDKProviderUtils/Delay.swift
Test:  Tests/AISDKProviderUtilsTests/DelayTests.swift
```

**âš ï¸ Header required**:
```swift
/**
 Brief description.

 Port of `@ai-sdk/provider-utils/src/delay.ts`.
 */
```

### 3. Port ALL Tests

Port every test case from `.test.ts` to Swift Testing:
- Same test names (camelCase)
- Same test data and edge cases
- **100% coverage required**

### 4. Verify & Validate

```bash
swift build && swift test           # Must pass
# Create .orchestrator/requests/... entry & update flow JSON (status=ready_for_validation)
# Automation will launch validator and handle the cycle
```
See `plan/orchestrator-automation.md` for templates and flow schema.

---

## Parity Standards

### Must Match
- âœ… Public API (names, parameters, types)
- âœ… Behavior (edge cases, errors)
- âœ… Error messages (same text)
- âœ… Test scenarios (all ported)

### Allowed Adaptations
- âœ… `Promise<T>` â†’ `async throws -> T`
- âœ… `AbortSignal` â†’ `@Sendable () -> Bool`
- âœ… Union types â†’ `enum` with associated values
- âœ… `undefined` â†’ `nil`
- âœ… `Record<K, V>` â†’ `[K: V]`

**Document adaptations** with rationale. See `plan/principles.md`.

---

## TypeScript â†’ Swift Patterns

| TypeScript | Swift |
|------------|-------|
| `Promise<T>` | `async throws -> T` |
| `value?: T \| undefined` | `value: T? = nil` |
| `type A \| B` | `enum Result { case a(A), case b(B) }` |
| `Record<K, V>` | `[K: V]` |
| `AbortSignal` | `@Sendable () -> Bool` |

---

## Current Status

**âœ… Completed** (763/763 tests passing):
- **AISDKProvider** (78 files, ~210 tests): LanguageModelV2/V3, EmbeddingModel, ImageModel, SpeechModel, TranscriptionModel, Errors, JSONValue
- **AISDKProviderUtils** (35 files, ~200 tests): HTTP/JSON utilities, Schema, Tools, Data handling
- **SwiftAISDK** (105 files, ~300 tests): Prompt conversion, Tool execution, Registry, Middleware, Telemetry
- **EventSourceParser** (2 files, 30 tests)

**ğŸš§ Next**: Block E/F (Generate/Stream Text), Provider implementations

**Stats**: ~14,300 lines, 220 files, 3 packages

---

## Key Commands

```bash
# Find upstream
ls external/vercel-ai-sdk/packages/*/src/

# Build & test
swift build && swift test

# Session contexts
cat .sessions/README.md

# Validation
cat plan/orchestrator-automation.md

# UTC timestamp
date -u +"%Y-%m-%dT%H:%M:%SZ"
```

---

## Testing & Race Condition Detection

### Smart Test Runner

**Location**: `tools/test-runner.js`

**Purpose**: Detect hanging tests, race conditions, and flaky test behavior through multi-run analysis.

#### Smart Mode (`--smart`)

Runs tests multiple times to identify race conditions and unstable tests:

```bash
# Run smart mode with 3 iterations and 5s timeout
node tools/test-runner.js --smart --runs 3 --timeout 5000

# Analyze specific config
node tools/test-runner.js --smart --config test-runner.default.config.json --runs 5
```

**Smart Mode Features**:
- âœ… **Multi-run analysis**: Runs test suite N times to catch intermittent failures
- âœ… **Timeout detection**: Identifies tests that hang (race conditions)
- âœ… **Culprit identification**: Binary search to isolate problematic tests
- âœ… **Stability analysis**: Shows which tests fail sometimes vs always
- âœ… **Clean reporting**: Groups by suite, shows patterns

> ğŸ’¡ **Tip**: Run `swift build` once before invoking `node tools/test-runner.js ...`. A warm build keeps the first iteration fast and prevents false timeouts from cold compilation.

**Output Analysis**:
```
ğŸ¯ Smart Mode Analysis (3 runs)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Run 1: â±ï¸  TIMEOUT after 5000ms
Run 2: â±ï¸  TIMEOUT after 5000ms
Run 3: âœ… PASSED (763 tests)

âš ï¸ Culprits Found: 2 tests/groups causing timeouts
  - SwiftAISDKTests.CreateUIMessageStreamTests/*
  - SwiftAISDKTests.HandleUIMessageStreamFinishTests/*
```

#### Standard Modes

**Exclude mode** (default):
```bash
# Run all tests EXCEPT listed patterns
node tools/test-runner.js --config test-runner.default.config.json
```

**Include mode**:
```bash
# Run ONLY specific tests
node tools/test-runner.js --config test-suspicious.config.json
```

**Options**:
- `--list` â€” Show all available tests
- `--dry-run` â€” Preview what will run without executing
- `--cache` â€” Use cached test list (faster, use only if tests haven't changed)
- `--timeout <ms>` â€” Timeout per run (default: 15000)
- `--runs <n>` â€” Number of iterations for smart mode (default: 3)

#### Configuration

Config files in `tools/`:
- `test-runner.default.config.json` â€” Run all tests (exclude mode)
- See `tools/README.md` for full documentation

**When to Use**:
- ğŸ” **After adding async/concurrent code** â€” Verify no race conditions introduced
- ğŸ› **Flaky test debugging** â€” Use `--smart` to reproduce intermittent failures
- â±ï¸ **Timeout investigation** â€” Smart mode identifies which tests hang
- âœ… **Pre-commit validation** â€” Quick sanity check with default config

**See**: `tools/README.md` for detailed documentation and examples.

---

## Pre-Completion Checklist

- [ ] Public API matches upstream
- [ ] Behavior matches exactly
- [ ] ALL upstream tests ported
- [ ] All tests pass
- [ ] Upstream reference in file header
- [ ] Adaptations documented
- [ ] `swift build` succeeds
- [ ] `.orchestrator/requests/...` created with summary
- [ ] `.orchestrator/flow/<executor-id>.json` updated (status=ready_for_validation)

---

## Key Principles

1. **ğŸš¨ NEVER TOUCH OTHER AGENTS' WORK** â€” Only edit your task files. Multiple agents work in parallel.
2. **Automation owns the loop** â€” Executors/validators must maintain `.orchestrator/` artifacts; the watcher handles validation.
3. **Flow JSON is authoritative** â€” Keep it valid/minified; use `status` (`working`, `ready_for_validation`, `needs_input`, etc.) accurately.
4. **Test everything** â€” 100% upstream parity and test coverage are mandatory.
5. **Mark done ONLY after validation** â€” Wait for automation to approve or explicitly document blockers.
6. **Never commit without permission** â€” Explicit user request required.
7. **Worktree defaults** â€” Executors on `auto`, validators on `manual` within executor worktree.

### Working in Git Worktrees

- Fresh worktrees do **not** include the upstream reference under `external/`. After creating a worktree, recreate the reference with:
  ```bash
  git clone https://github.com/vercel/ai external/vercel-ai-sdk
  cd external/vercel-ai-sdk
  git checkout 77db222ee  # upstream reference commit
  ```
- Keep the worktree on the correct Swift AI SDK commit (`b40920d4876a213194e0d16d9899abbb61ad9cab` as of 2025-10-16). Use `git status` regularly to ensure you stay aligned.
- Avoid editing shared upstream files inside the cloned reference; treat it as read-only.

---

## Documentation Files

### Core
- `README.md` â€” Project overview
- `AGENTS.md` â€” This file
- `Package.swift` â€” SwiftPM manifest

### Plan Directory
- `principles.md` â€” Porting guidelines
- `executor-guide.md` â€” Executor workflow
- `validation-workflow.md` â€” Validation process
- `validator-guide.md` â€” Manual checklist
- `design-decisions.md` â€” Documented deviations
- `tests.md` â€” Testing approach

### Validation Automation
- `plan/orchestrator-automation.md` â€” Flow schema & naming
- `plan/validation-workflow.md` â€” Automation + fallback process
- `.claude/agents/validator.md` â€” Validator prompt definition
- `.orchestrator/` (gitignored) â€” Runtime requests/reports/flow files

### Session Contexts
- `.sessions/README.md` â€” Context guide
- `.sessions/EXAMPLE-*.md` â€” Templates

---

## Resources

- **Upstream repo**: https://github.com/vercel/ai
- **EventSource parser**: https://github.com/EventSource/eventsource-parser
- **Swift Testing**: https://developer.apple.com/documentation/testing

---

## Quick Tips

### For Executors
- ğŸš¨ **Only edit your task files** â€” If other files fail, STOP and report
- ğŸš¨ **Never commit temp dirs** â€” `.sessions/`, `.orchestrator/` are gitignored
- ğŸ¤– **Trust automation** â€” Update flow/request files; manual MCP calls only for overrides
- âœ… Mark `in-progress` at start, `done` only after approval
- âœ… Port ALL tests, add upstream references
- âœ… Save session context for multi-session work
- âŒ Don't skip tests or commit without permission

### For Validators
- âœ… Follow automation prompts and update `.orchestrator/flow/<validator-id>.json`
- âœ… Check line-by-line parity, verify all tests ported
- âœ… Produce detailed reports in `.orchestrator/reports/`
- âŒ Don't accept "close enough"

---

**Remember**: Every line must match upstream. Keep `.orchestrator/flow` accurate so automation can enforce 100% parity.


# MCP Usage
Ğ”Ğ»Ñ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° MCP Ğº Ğ¿Ñ€Ğ¸Ğ¼ÑƒÑ€ taskmaster.get_tasks Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ´Ğ»Ñ MCP taskmaster

*Last updated: 2025-10-14*
